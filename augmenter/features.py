import logging
from functools import partial
from multiprocessing import Pool

import pandas as pd

from .markov import MarkovGenerator
from settings import TARGET_CLASS_COLUMN
from feature_processing import FEATURE_PREFIX, FEATURE_NAMES, calc_parameter_stats, create_empty_features


logger = logging.getLogger(__name__)

PACKET_FEATURES = tuple(name for name in FEATURE_NAMES if name.startswith('packet'))


def calc_flow_features_raw_packets(packet_vector):
    """ estimates flow features (packet-size derivatives) from the generated by augmenters,
     e.g. 'packet0', ... 'packet$N' """

    client_slice = packet_vector[packet_vector > 0]
    if client_slice.shape[0] > 0:
        client_features = calc_parameter_stats(client_slice,
                                               prefix=FEATURE_PREFIX.client,
                                               feature_name='packet')
    else:
        client_features = create_empty_features(prefix=FEATURE_PREFIX.client, feature_list=PACKET_FEATURES)

    server_slice = packet_vector[packet_vector < 0] * -1
    if server_slice.shape[0] > 0:
        server_features = calc_parameter_stats(server_slice,
                                               prefix=FEATURE_PREFIX.server,
                                               feature_name='packet')
    else:
        server_features = create_empty_features(prefix=FEATURE_PREFIX.server, feature_list=PACKET_FEATURES)

    total_features = dict(**client_features, **server_features)
    return total_features


def generate_target_class_samples(dataset, generator_class, target_name, augm_count):
    ds = dataset[dataset[TARGET_CLASS_COLUMN] == target_name]
    X = ds.drop(TARGET_CLASS_COLUMN, axis=1)
    feature_columns = X.columns
    X = X.values

    logger.info(f'augmenting {target_name} class with {augm_count} samples')
    generator = generator_class()
    generator.fit(X)
    gen = generator.sample(augm_count)
    gen = pd.DataFrame(gen, columns=feature_columns)
    gen[TARGET_CLASS_COLUMN] = pd.Series([target_name] * augm_count)
    return gen


def oversample_raw_packets(dataset: pd.DataFrame,
                           sampling_strategy=None,
                           generator_class=MarkovGenerator,
                           n_jobs=4):

    def _get_target_numbers_to_augment(y: pd.DataFrame) -> dict:
        target_counts = y.value_counts()
        target_number = target_counts.max()
        count_to_augment = (target_number - target_counts)
        return count_to_augment.to_dict()

    if sampling_strategy is None:
        sampling_strategy = _get_target_numbers_to_augment(dataset[TARGET_CLASS_COLUMN])
    # remove 0 targets
    sampling_strategy = dict(filter(lambda x: x[1], sampling_strategy.items()))
    with Pool(processes=n_jobs) as pool:
        generated = pool.starmap(partial(generate_target_class_samples, dataset, generator_class),
                                 sampling_strategy.items())

    return pd.concat(generated)
